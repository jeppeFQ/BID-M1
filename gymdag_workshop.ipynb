{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsSS1f3STai6YPp9Mbw649",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeppeFQ/BID-M1/blob/main/gymdag_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduktion\n",
        "\n",
        "## Natural Language Processing (NLP)\n",
        "\n",
        "Natural Language Processing (**NLP**) er et centralt felt indenfor **AI** (kunstig intelligens). Grundlæggende handler NLP om hvordan en computer kan forstå og fortolke *naturligt sprog*, dvs. menneskeligt talt sprog. Gerne opgaven er at maskiner kan bearbejde dette sprog (og endda kunne producere det).\n",
        "\n",
        "Med NLP kan maskiner bearbejde tekst og tale på samme måde, som mennesker gør.\n",
        "\n",
        "> **Spg.:** Hvad vil det sige at et sprog er naturligt?\n",
        "\n",
        "## Oversættelsesperspektiv\n",
        "\n",
        "Computeren ikke sprog på samme måde som mennesker gør. De kan læse `1` og de kan læse `0`; men de kan sætte disse tegn sammen i uendelige rækker af varierende kompleksitet. Dvs. mønstre af binære numeriske inputs. NLP handler om at bygge bro mellem den måde, mennesker kommunikerer på, og hvordan maskiner forstår data.\n",
        "\n",
        "**En IKKE-UDTØMMENDE liste af grundlæggende elementer i oversættelse af naturligt sprog til maskin-læsbart sprog**:\n",
        "\n",
        "1. ***Tokenization***, som handler om at dele en tekst op i mindre dele, ofte ord eller sætninger. En sætning som \"Jeg elsker data!\" blive delt op i tre(fire) tokens: [\"Jeg\", \"elsker\", \"data\", \"!\"].\n",
        "\n",
        "2. **Stemming og Lemmatization**, som reducerer ord til deres grundform. Fx bliver \"løbende\" og \"løber\" reduceret til roden, \"løb\".\n",
        "\n",
        "3. **Part-of-Speech Tagging** (POS Tagging), som identificerer ordklasser (som verber, substantiver osv.) for hvert ord i en sætning, hvilket gør det muligt at forstå ordenes funktion i sætningen. [*Ikke aktuelt i dagens workshop*]\n",
        "\n",
        "4. **Named Entity Recognition** (NER), som identificerer navne på personer, steder eller organisationer i en tekst. For eksempel i sætningen \"Aalborg Universitet er et universitet i Danmark\" vil \"Aalborg Universitet\" blive genkendt som en organisation og \"Danmark\" som et land. [*Ikke aktuelt i dagens workshop*]\n",
        "\n",
        "Dette oversættelsesperspektiv i en digital kontekst er centralt i dagens workshop.\n",
        "\n",
        "## Klassifikation i NLP\n",
        "\n",
        "Et almindeligt \"opgave\" eller problem i NLP er **klassifikation**. Klassifikation handler om at *tildele et label til en tekst baseret på dens indhold*. I praksis er det en proces, hvor vi anvender en (klassifikations)**algoritme** på et stykke tekst for at **forudsige** den klasse som teksten hører til.\n",
        "\n",
        "## Superviseret Machine Learning (SML)\n",
        "\n",
        "I dag er fokus kun på superviseret ML, da vi kun har en enkelt workshop i dag og der vil være for mange statistiske forudsætninger til de to andre hovedtyper.\n",
        "\n",
        "**SML** fungerer ved, at vi giver `modellen` data, hvor vi kender det rigtige svar. Det kunne være, om en besked er *spam eller ej*, om et produkt er populær baseret på salgsdata, eller hvilken temperatur der vil være i morgen baseret på historiske målinger.\n",
        "\n",
        "> I besked eksemplet vil det altså sige at vi har et datasæt bestående af SMSer, hvor hver SMS i den data vi træner vores model på er `kodet`, dvs. tilskrevet et `label`, der indikerer om SMSen er spam (`label=1`) eller ikke-spam -- \"ham\" -- (`label=0`).\n",
        "\n",
        "Modellen lærer sammenhænge mellem de inputdata (`features`, ord), som vi fodrer den med, og de kendte svar (`labels`, spam/ham). Når modellen er trænet, og den er vurderet til at være god nok, kan vi bruge den til at forudsige `labels` for nye data, hvor vi ikke kender svaret på forhånd."
      ],
      "metadata": {
        "id": "_uhpe4VcdBta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop"
      ],
      "metadata": {
        "id": "dm-wtrqFebjx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8EjWo6VceVa",
        "outputId": "99bbcf0e-b110-4b0a-aac7-e36e4f572ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "5  Probably my all-time favorite movie, a story o...  positive\n",
            "6  I sure would like to see a resurrection of a u...  positive\n",
            "7  This show was an amazing, fresh & innovative i...  negative\n",
            "8  Encouraged by the positive comments about this...  negative\n",
            "9  If you like original gut wrenching laughter yo...  positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nijatmammadov/review-classification-nlp/refs/heads/master/IMDB%20Dataset.csv'\n",
        "data = pd.read_csv(url, sep=\",\")\n",
        "\n",
        "print(data.head(10))\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Altså,\\\n",
        "Modellens formål er at lære forholdet mellem de inputdata, vi giver den (`features`, \"review\"), og de kendte `labels` (\"sentiment\"), så den kan **forudsige** `labels` for *nye, ukendte data*.\n",
        "\n",
        "Det vil altså sige at vi har med et **klassifikationsproblem** at gøre. Modellen skal forudsige, hvilken kategori noget tilhører, og virke som et spam-filter, hvor vi klassificerer beskeder som enten \"spam\" eller \"ikke-spam\", og i en praktisk applikation kan sende indkomne beskeder ind i forskellige mapper, som I kender fra jeres e-mail."
      ],
      "metadata": {
        "id": "WZUESjP2emVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeltræning\n",
        "\n",
        "I arbejdet med superviseret Machine Learning arbejder vi med vores data som opdelt i hhv. `trænings-` og `testdata`. Den data vi arbejder med, er et datasæt som vi har **kvalitativt kodet** med de korrekte labels ud fra vores forhåndsviden. Med denne opdeling er det muligt både at *træne vores model* og *evaluere vores model*, for at kunne vurdere hvordan modellen performer på nye, usete data.\n",
        "\n",
        "## **Test**data\n",
        "\n",
        "Testdata udgør den anden del af den kvalitativt kodede data (her 20%). Testdataene bruges til at evaluere modelens præstation og generaliseringsevne og formålet med testdata er at give et mål for, hvordan modellen vil præstere på nye, usete data. Det vil altså sige at modellen ikke har \"set\" denne data (og er grunden til at vi skal have Laplace Smoothing...)\n",
        "\n",
        "## **Opslitning** af data\n",
        "\n",
        "I Python opslitter vi dataen ved at anvende funktionen `train_test_split` fra `sklearn.model_selection` modulet."
      ],
      "metadata": {
        "id": "rRfzwTUrfEqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Data er vores DataFrame med anmeldelser og labels\n",
        "X = data['review']  # Tekst-indholdet (features)\n",
        "y = data['sentiment']  # Labels (targets)"
      ],
      "metadata": {
        "id": "4vgpEI0HfX6R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyIId7IYfjdF",
        "outputId": "dc367918-bf0b-43f9-8270-7c5d4673cbb6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        One of the other reviewers has mentioned that ...\n",
            "1        A wonderful little production. <br /><br />The...\n",
            "2        I thought this was a wonderful way to spend ti...\n",
            "3        Basically there's a family where a little boy ...\n",
            "4        Petter Mattei's \"Love in the Time of Money\" is...\n",
            "                               ...                        \n",
            "49995    I thought this movie did a down right good job...\n",
            "49996    Bad plot, bad dialogue, bad acting, idiotic di...\n",
            "49997    I am a Catholic taught in parochial elementary...\n",
            "49998    I'm going to have to disagree with the previou...\n",
            "49999    No one expects the Star Trek movies to be high...\n",
            "Name: review, Length: 50000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data i trænings- og test-sæt.\n",
        "# Random state er et \"seed\", der bestemmer det tilfældige udtræk.\n",
        "# Hvis i har samme random state som her, skulle I få samme resultat.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "3uPjSrbjv-an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CHh70yGfn70",
        "outputId": "a152b6bc-be4e-4551-aae7-ddc0d061fa41"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11872    This movie was beyond awful, it was a pimple o...\n",
            "40828    As of this writing John Carpenter's 'Halloween...\n",
            "36400    I must admit a slight disappointment with this...\n",
            "5166     Oh dear! The BBC is not about to be knocked of...\n",
            "30273    its a totally average film with a few semi-alr...\n",
            "                               ...                        \n",
            "5703     I liked this movie. Unlike other thrillers you...\n",
            "36992    I've seen this movie more than once. It was on...\n",
            "14005    There have been many movies about people retur...\n",
            "29455    Heftig og Begeistret (Intense and Enthusiastic...\n",
            "36904    This is probably Karisma at her best, apart fr...\n",
            "Name: review, Length: 10000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnQUzXcxfsff",
        "outputId": "54702ee2-7ed0-42f5-b08d-2c774c3b9070"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11872    negative\n",
            "40828    positive\n",
            "36400    positive\n",
            "5166     negative\n",
            "30273    negative\n",
            "           ...   \n",
            "5703     positive\n",
            "36992    positive\n",
            "14005    positive\n",
            "29455    negative\n",
            "36904    positive\n",
            "Name: sentiment, Length: 10000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes klassifikation i praksis\n",
        "\n",
        "Repitation af formål og hvad vi vil implementere i Python er:  \n",
        "\n",
        "> Sandsynligheden for at en anmeldelse er positiv, baseret på fremkomsten/tilstedeværelsen af et givent ord, er proportionelt til sandsynligheden for at ordet fremkommer i positive anmeldelser og den *a priori* sandsynlighed for at en tilfældig anmeldelse er positiv\n",
        "\n",
        "$$\n",
        "P(\\text{positiv}|ord)\\propto P(ord|\\text{positiv}) P(\\text{positiv})\n",
        "$$\n",
        "\n",
        "> **Spg.:** Hvordan implimenterer vi denne model i Python på en måde, der kan \"lære\" maskinen at genkende spam-SMSer?"
      ],
      "metadata": {
        "id": "PRf8Xry2gBZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Indlæs ML/AI biblioteker\n",
        "\n"
      ],
      "metadata": {
        "id": "-kolRNbwgOIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
      ],
      "metadata": {
        "id": "ur_rKNangNkj"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Bag-of-Word vektorisering"
      ],
      "metadata": {
        "id": "MhGTnquygd0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Liste af stopord\n",
        "yderlige_stop_words = {\"movie\", \"film\", \"like\", \"br\", \"story\", \"people\"}\n",
        "stop_words = list(ENGLISH_STOP_WORDS.union(yderlige_stop_words))\n",
        "\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOsPTUcCgkeb",
        "outputId": "847a6474-f95a-41cb-cef6-158f9c001425"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nobody', 'hereupon', 'made', 'former', 'much', 'his', 'thus', 'six', 'ever', 'elsewhere', 'because', 'nevertheless', 'what', 'inc', 'thru', 'four', 'call', 'is', 'too', 'whereas', 'twelve', 'together', 'then', 'anyway', 'behind', 'such', 'give', 'neither', 'during', 'should', 'con', 'thereafter', 'on', 'story', 'fire', 'never', 'how', 'ltd', 'latterly', 'he', 'several', 'full', 'throughout', 'become', 'almost', 'mine', 'except', 'meanwhile', 'same', 'everywhere', 'here', 'de', 'people', 'put', 'somewhere', 'that', 'we', 'however', 'seems', 'via', 'ourselves', 'for', 'yourselves', 'her', 'became', 'of', 'hers', 'own', 'un', 'first', 'whose', 'whence', 'hundred', 'nowhere', 'the', 'with', 'co', 'so', 'itself', 'describe', 'take', 'fifty', 'hereby', 'among', 'nor', 'from', 'within', 'might', 'go', 'but', 'me', 'something', 'etc', 'who', 'why', 'hence', 'off', 'as', 'namely', 'fifteen', 'between', 'beside', 'about', 'else', 'thereby', 'whereupon', 'serious', 'none', 'found', 'well', 'name', 'latter', 'moreover', 'yet', 'at', 'your', 'part', 'it', 'always', 'only', 'sometime', 'without', 'us', 'whole', 'in', 'when', 'per', 'whom', 'rather', 'nothing', 'back', 'themselves', 'a', 'fill', 'which', 'any', 'sixty', 'either', 'less', 'front', 'anyhow', 'anything', 'move', 'had', 'even', 'around', 'next', 'both', 'empty', 'therefore', 'now', 'towards', 'seeming', 'you', 'whether', 'most', 'be', 'eg', 'until', 'cant', 'where', 'wherever', 'through', 'besides', 'not', 'enough', 'whereafter', 'do', 'more', 'please', 'along', 'seem', 'mostly', 'again', 'least', 'br', 'two', 'no', 'by', 'must', 'hasnt', 'herein', 'every', 'whereby', 'wherein', 'yourself', 'ours', 'third', 'becomes', 'formerly', 'than', 'its', 'movie', 'toward', 'system', 'am', 'whither', 'also', 'get', 'our', 'noone', 'their', 'yours', 'thin', 'further', 'upon', 'anyone', 'will', 'onto', 'forty', 'already', 'these', 'was', 'whenever', 'another', 'everyone', 'amoungst', 'other', 'would', 'were', 'indeed', 'ten', 'five', 'twenty', 'an', 'done', 'she', 'those', 'against', 'interest', 'himself', 'thereupon', 'whatever', 'into', 'bill', 'many', 'amongst', 'over', 'seemed', 'thick', 'hereafter', 'or', 'all', 'thence', 'ie', 'though', 'others', 'sometimes', 'i', 'everything', 'detail', 'film', 'someone', 'have', 'some', 'down', 'therein', 'above', 'still', 'they', 'to', 'three', 'otherwise', 'eleven', 'last', 'one', 'keep', 'sincere', 'my', 'since', 'find', 'very', 'show', 'becoming', 'few', 'although', 'nine', 'eight', 'often', 'across', 'out', 'cry', 'being', 'cannot', 'under', 'herself', 'mill', 'like', 'somehow', 'couldnt', 'afterwards', 'could', 'top', 'due', 'and', 'up', 'are', 'after', 'bottom', 'him', 'may', 'before', 'amount', 'this', 'perhaps', 'been', 'beforehand', 'see', 'if', 'side', 'beyond', 'them', 'can', 'anywhere', 'whoever', 'while', 'has', 'once', 'below', 'alone', 'there', 'myself', 'each', 're']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisering af CountVectorizer-klassen med stopord og filtre for ikke- og særligt fremkomne ord\n",
        "vectorizer_bow = CountVectorizer(stop_words=stop_words, min_df=1, max_df=0.75)"
      ],
      "metadata": {
        "id": "0ohKXhhYwdiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer er en klasse i scikit-learn.\n",
        "# Når vi kører vectorizer_bow = CountVectorizer() initialicerer vi klasse\n",
        "# med basis \"indstillingerne\" relateret til klasse (i.e., indbyggede metoder og datastruktur)\n",
        "# Eller de specikke indstillinger vi giver som indput (max_df=0.75, stop_words='english'). min_df=1 er default.\n",
        "# Derfor får vi bare:\n",
        "print(vectorizer_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DstTDVnUgoO1",
        "outputId": "9743d90e-821f-4413-8939-6059b8baa54b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer(max_df=0.75,\n",
            "                stop_words=['nobody', 'hereupon', 'made', 'former', 'much',\n",
            "                            'his', 'thus', 'six', 'ever', 'elsewhere',\n",
            "                            'because', 'nevertheless', 'what', 'inc', 'thru',\n",
            "                            'four', 'call', 'is', 'too', 'whereas', 'twelve',\n",
            "                            'together', 'then', 'anyway', 'behind', 'such',\n",
            "                            'give', 'neither', 'during', 'should', ...])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer træningsdata (Splittet fra X) til BoW\n",
        "X_train_bow = vectorizer_bow.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "epzomWpWgqTn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.fit_transform()` er en dedikeret metode i `CountVectorizer` klassen:\n",
        "\n",
        "1. `fit_transform` er \"indkapslet\" i `CountVectorizer` klassen.\n",
        "\n",
        "2. Vi behøves derfor ikke vide detaljerne i hvordan metoden vektoriserer vores data givet input, da dette er abstrakseret i det simple kald: `klasse.metode(input)`\n",
        "\n",
        "3. `fit_transform` \"tilhører\" derfor også klassen og opererer kun på data, vi associerer med denne klasse. Vi gør det med `associeret data` = `klasse.metode(input)`.\n",
        "  1. `fit`: er en metode til at definere den interne data, givet som vektor af unikke ord og deres frekvenser.\n",
        "  2. `transform`: transform er en metode, der transformere data indputtet til den interne datastruktur som numeriske repræsentationer for hvert ord (en matrice med ordfrekvenser)"
      ],
      "metadata": {
        "id": "9SdYhQVpgs-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQp3KcYKg4QA",
        "outputId": "92459da0-ba01-46ed-d78b-fd5a6b6df8ad"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 58078)\t1\n",
            "  (0, 77134)\t1\n",
            "  (0, 24220)\t2\n",
            "  (0, 45630)\t3\n",
            "  (0, 17900)\t1\n",
            "  (0, 34157)\t1\n",
            "  (0, 41406)\t1\n",
            "  (0, 79035)\t1\n",
            "  (0, 48120)\t1\n",
            "  (0, 71446)\t1\n",
            "  (0, 79835)\t2\n",
            "  (0, 89116)\t1\n",
            "  (0, 78923)\t1\n",
            "  (0, 31307)\t1\n",
            "  (0, 12090)\t1\n",
            "  (0, 91984)\t1\n",
            "  (0, 77225)\t3\n",
            "  (0, 32945)\t3\n",
            "  (0, 14991)\t1\n",
            "  (0, 90459)\t2\n",
            "  (0, 80783)\t1\n",
            "  (0, 91264)\t1\n",
            "  (0, 28500)\t2\n",
            "  (0, 90470)\t1\n",
            "  (0, 33794)\t3\n",
            "  :\t:\n",
            "  (39999, 22614)\t1\n",
            "  (39999, 27820)\t1\n",
            "  (39999, 57684)\t1\n",
            "  (39999, 25078)\t2\n",
            "  (39999, 1854)\t1\n",
            "  (39999, 66494)\t1\n",
            "  (39999, 6809)\t1\n",
            "  (39999, 34297)\t1\n",
            "  (39999, 72832)\t1\n",
            "  (39999, 34190)\t1\n",
            "  (39999, 64164)\t1\n",
            "  (39999, 41330)\t1\n",
            "  (39999, 46678)\t1\n",
            "  (39999, 64159)\t1\n",
            "  (39999, 40937)\t1\n",
            "  (39999, 25135)\t1\n",
            "  (39999, 32631)\t1\n",
            "  (39999, 5056)\t1\n",
            "  (39999, 20995)\t1\n",
            "  (39999, 35079)\t1\n",
            "  (39999, 15487)\t1\n",
            "  (39999, 71594)\t1\n",
            "  (39999, 37618)\t1\n",
            "  (39999, 46510)\t2\n",
            "  (39999, 15997)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer testdata\n",
        "# I testdataen bruger vi den allerede definerede ordliste fra træningsdataene.\n",
        "# og behøves derfor ikke også at kalde fit.\n",
        "X_test_bow = vectorizer_bow.transform(X_test)"
      ],
      "metadata": {
        "id": "FJX2U04DhDnw"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF9xmr5ihLAr",
        "outputId": "33f9fa0d-6779-4010-a6be-842a88e7f545"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 38)\t1\n",
            "  (0, 1584)\t1\n",
            "  (0, 1881)\t1\n",
            "  (0, 4805)\t1\n",
            "  (0, 6427)\t1\n",
            "  (0, 6548)\t1\n",
            "  (0, 8871)\t1\n",
            "  (0, 9073)\t1\n",
            "  (0, 10287)\t1\n",
            "  (0, 11874)\t1\n",
            "  (0, 13700)\t1\n",
            "  (0, 17847)\t1\n",
            "  (0, 19215)\t1\n",
            "  (0, 25135)\t1\n",
            "  (0, 25306)\t1\n",
            "  (0, 27421)\t1\n",
            "  (0, 30404)\t1\n",
            "  (0, 30926)\t1\n",
            "  (0, 33755)\t1\n",
            "  (0, 34904)\t1\n",
            "  (0, 36744)\t1\n",
            "  (0, 37472)\t1\n",
            "  (0, 37476)\t1\n",
            "  (0, 37796)\t1\n",
            "  (0, 38478)\t1\n",
            "  :\t:\n",
            "  (9999, 47047)\t1\n",
            "  (9999, 47155)\t1\n",
            "  (9999, 53942)\t1\n",
            "  (9999, 54557)\t1\n",
            "  (9999, 55613)\t1\n",
            "  (9999, 59131)\t1\n",
            "  (9999, 60413)\t1\n",
            "  (9999, 61129)\t1\n",
            "  (9999, 61901)\t1\n",
            "  (9999, 63268)\t1\n",
            "  (9999, 64031)\t1\n",
            "  (9999, 64241)\t1\n",
            "  (9999, 66658)\t1\n",
            "  (9999, 66692)\t2\n",
            "  (9999, 73053)\t1\n",
            "  (9999, 73260)\t1\n",
            "  (9999, 73764)\t1\n",
            "  (9999, 78041)\t1\n",
            "  (9999, 79771)\t1\n",
            "  (9999, 82479)\t1\n",
            "  (9999, 82705)\t1\n",
            "  (9999, 84566)\t1\n",
            "  (9999, 87634)\t1\n",
            "  (9999, 89299)\t1\n",
            "  (9999, 92475)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modellering af data\n",
        "\n",
        "Med samme logik initialiserer vi her et Naive Bayes objekt, til at indkapse data i den rette struktur og modellerede sandsynligheder fra træning og forudsigelse. Vi organiserer altså de to analytiske dimensioner: træning og test.\n",
        "\n",
        "Hermed er den ellers meget komplekse kode derfor abstrakseret, således at vi har en slagt \"interface\" med nogle dedikerede og relevante metoder (her fx `fit` og `predict`).\n",
        "\n",
        "Det gør det derfor ligefremt at udvide eller ændre vores model og analyse, idet vi kan bruge de identistiske metoder for andre algoritmer end kun Naive Bayes, uden det kræver nye former for implementering af kode (nedarvning og foranderlighed)."
      ],
      "metadata": {
        "id": "B-XNPNLVhShZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes-model\n",
        "model_bow = MultinomialNB()\n",
        "print(model_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzB3DaLchX-p",
        "outputId": "d5b221a3-616e-493f-a51d-0b05e993d29a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Træn modellen og tilskriv de trænede sandsynligheder til objektet \"model_bow\"\n",
        "model_bow.fit(X_train_bow, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "_7KrC-hIhiTU",
        "outputId": "9dac4cc4-06ac-42ed-ff38-bfe7ce4ed0f6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Alt det følgende behøves i ikke at forstå. Det er udelukkende for at printe\n",
        "# sandsynligheder for de enkelte ord fra vores NB model.\n",
        "\n",
        "## Udtræk sandsynlighederne fra modeller\n",
        "feature_names = vectorizer_bow.get_feature_names_out()\n",
        "\n",
        "log_prob = model_bow.feature_log_prob_\n",
        "\n",
        "probabilities = np.exp(log_prob)\n",
        "\n",
        "df_probs = pd.DataFrame(probabilities.T, columns=model_bow.classes_, index=feature_names)\n",
        "\n",
        "## Top-10 prd\n",
        "n_top = 10\n",
        "\n",
        "## Loop gennem hver klasse\n",
        "for class_label in df_probs.columns:\n",
        "    print(f\"\\nKlasse: {class_label}\")\n",
        "\n",
        "    # Sort words by probability for the current class\n",
        "    sorted_probs = df_probs[class_label].sort_values(ascending=False)\n",
        "\n",
        "    # Get top N words\n",
        "    top_words = sorted_probs.head(n_top)\n",
        "    print(\"\\nOrd med de højeste sandsynligheder for klassen:\")\n",
        "    for word, prob in top_words.items():\n",
        "        print(f\"{word}: {prob:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meHpP6ryqTSn",
        "outputId": "7133c6dc-a850-4101-8b43-de7bbe34444a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Klasse: negative\n",
            "\n",
            "Ord med de højeste sandsynligheder for klassen:\n",
            "just: 0.0080\n",
            "bad: 0.0057\n",
            "good: 0.0056\n",
            "time: 0.0048\n",
            "really: 0.0048\n",
            "don: 0.0041\n",
            "make: 0.0036\n",
            "movies: 0.0032\n",
            "plot: 0.0032\n",
            "acting: 0.0031\n",
            "\n",
            "Klasse: positive\n",
            "\n",
            "Ord med de højeste sandsynligheder for klassen:\n",
            "good: 0.0055\n",
            "just: 0.0052\n",
            "great: 0.0048\n",
            "time: 0.0047\n",
            "really: 0.0039\n",
            "love: 0.0032\n",
            "best: 0.0031\n",
            "life: 0.0030\n",
            "way: 0.0029\n",
            "films: 0.0028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Kunne man tænke at mere tid på databehandling ville være nyttig?"
      ],
      "metadata": {
        "id": "wBANTGfhtJqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Forudsig på testdata og tilskriv de estimerede sandsynligheder til \"model_bow\" objektet\n",
        "y_pred_bow = model_bow.predict(X_test_bow)\n",
        "print(y_pred_bow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAGzGTuVhoCG",
        "outputId": "2ce962eb-b0b5-4b88-e7dc-fa27f6e4a90f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['negative' 'positive' 'positive' ... 'positive' 'positive' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opsummeret\n",
        "\n",
        "1. Vi initialiserer et objekt (instance) ved at kalde `model_bow = MultinomialNB()`. Et objekt med dets egen interne data- og inputstruktur (i.e., numerisk repræsentation af data og modellerede sandsynligheder) og dedikerede metoder til at bearbejde og tilgå disse informationer.\n",
        "**Vi interagerer med objektet og dets data vha. objektets indbyggede metoder:**\n",
        "2. Med den indbyggede `fit`-metode kan vi træne en NB model på den tilskrevne data og *opdatere objektets interne tilstand*.\n",
        "3. Med den indbyggede `predict`-metode kan vi udregne forudsagte sandsynligheder og klasser og gemme/tilskrive denne data til objektet og igen  *opdaterer vi objektets interne tilstand*.     \n",
        "**Det centrale er at alle detaljer om algoritme forbliver \"skujlt\" for brugeren, da den er indbygget i objektet og initialiseres vha. de indbyggede metoder i en slags interface.**\n"
      ],
      "metadata": {
        "id": "T9SwBQkAjpWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test og evaluering"
      ],
      "metadata": {
        "id": "Ud3VytsXjXz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Korrekt Label\": y_test,\n",
        "    \"Forudsagt Label\": y_pred_bow\n",
        "})\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy5tIO_iAhx",
        "outputId": "4c1de12b-1637-4e36-9ef1-71ff6beaabf7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Korrekt Label Forudsagt Label\n",
            "11872      negative        negative\n",
            "40828      positive        positive\n",
            "36400      positive        positive\n",
            "5166       negative        positive\n",
            "30273      negative        negative\n",
            "...             ...             ...\n",
            "5703       positive        positive\n",
            "36992      positive        negative\n",
            "14005      positive        positive\n",
            "29455      negative        positive\n",
            "36904      positive        positive\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluering af modellen\n",
        "# Vi tager den oprindelige data med de \"ægte\" labels (y_test) og den data vi konstruerer (y_pred_bow)\n",
        "# med vores trænede model gemt i objektet (model_bow).\n",
        "# Disse to vektorer af værdier (rigtigt og forudsagt label) og udregner evalueringsmål med funktionen classification_report()\n",
        "print(\"Naive Bayes med BoW pre-processing af naturligt sprog\\n\\n\")\n",
        "print(classification_report(y_test, y_pred_bow))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQNH-PVdkdNo",
        "outputId": "4d4a1da0-c2a4-48f8-b5f2-c6d0f7bfe014"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes med BoW pre-processing af naturligt sprog\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.87      0.86      4979\n",
            "    positive       0.87      0.84      0.86      5021\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hvad kan i gøre herfra (sammen med elever)\n",
        "\n",
        "- https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/L4OAKN\n",
        "\n",
        "- https://manifesto-project.wzb.eu/datasets/MPDS2024a\n",
        "\n",
        "- https://github.com/erikgahner/PolData\n",
        "\n",
        "### 1. Håndkodning af ny data (scrapet eller downloadet)\n",
        "\n",
        "### 2. Øv med allerede eksisterende data\n"
      ],
      "metadata": {
        "id": "L5VyC48gk6Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Spam-filter**\n",
        "\n",
        "## Konkret øvelse til at gå i gang med:\n",
        "\n",
        "> Det eneste, der skal ændres ift. koden ovenfor er at i koden nedenfor hedder kolonnerne ikke \"review\" og \"sentiment\". Brug `print(data)` for at se hvad variablene hedder i den nye data\n",
        "\n",
        "```\n",
        "X = data['review']  # Tekst-indholdet (features)\n",
        "y = data['sentiment']  # Labels (targets)\n",
        "```\n",
        "\n",
        "Derudover skal de \"yderlige stopord\" sandsynligvis også ændres. Eller ej?\n",
        "\n",
        "```\n",
        "# Liste af stopord\n",
        "yderlige_stop_words = {\"movie\", \"film\", \"like\", \"br\", \"story\", \"people\"}\n",
        "stop_words = list(ENGLISH_STOP_WORDS.union(yderlige_stop_words))\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OZU9qpthloDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/manjit-baishya-datascience/Spam-Email-Detection/refs/heads/main/email_data.csv'\n",
        "data = pd.read_csv(url, sep=\",\")\n",
        "\n",
        "print(data.head(10)) # HINT: navnene er \"Category\", der skal være `y` og \"Message\" som skal være `X`\n",
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP87FBAxmMDg",
        "outputId": "e1813efa-5dfb-4f19-b347-1d0858e60e5b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category                                            Message\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "5     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
            "6      ham  Even my brother is not like to speak with me. ...\n",
            "7      ham  As per your request 'Melle Melle (Oru Minnamin...\n",
            "8     spam  WINNER!! As a valued network customer you have...\n",
            "9     spam  Had your mobile 11 months or more? U R entitle...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5572"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dansk tekst\n",
        "\n",
        "Skal I have danske stopord er processen:\n"
      ],
      "metadata": {
        "id": "JqXmywWWyz-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By0hJHtHy-lj",
        "outputId": "38b1461a-e534-4a42-8e66-10795f7df6a3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Download stopord\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Danske stopord liste\n",
        "danske_stop_ord = stopwords.words('danish')\n",
        "\n",
        "# Yderlige stopord, hvis relevant\n",
        "stop_words = danske_stop_ord + [\"customword1\", \"customword2\"]\n",
        "\n",
        "print(stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a1QHv7My55S",
        "outputId": "da05e8a4-2c9b-48e1-9f06-9865945a1f2c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['og', 'i', 'jeg', 'det', 'at', 'en', 'den', 'til', 'er', 'som', 'på', 'de', 'med', 'han', 'af', 'for', 'ikke', 'der', 'var', 'mig', 'sig', 'men', 'et', 'har', 'om', 'vi', 'min', 'havde', 'ham', 'hun', 'nu', 'over', 'da', 'fra', 'du', 'ud', 'sin', 'dem', 'os', 'op', 'man', 'hans', 'hvor', 'eller', 'hvad', 'skal', 'selv', 'her', 'alle', 'vil', 'blev', 'kunne', 'ind', 'når', 'være', 'dog', 'noget', 'ville', 'jo', 'deres', 'efter', 'ned', 'skulle', 'denne', 'end', 'dette', 'mit', 'også', 'under', 'have', 'dig', 'anden', 'hende', 'mine', 'alt', 'meget', 'sit', 'sine', 'vor', 'mod', 'disse', 'hvis', 'din', 'nogle', 'hos', 'blive', 'mange', 'ad', 'bliver', 'hendes', 'været', 'thi', 'jer', 'sådan', 'customword1', 'customword2']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    }
  ]
}